"""
å€™é€‰ Provider é‡è¯•é€»è¾‘

æå–éæµå¼å’Œæµå¼è¯·æ±‚ä¸­é‡å¤çš„å€™é€‰éå†å’Œé‡è¯•é€»è¾‘
"""

import json
from collections.abc import Awaitable, Sequence
from typing import Any, Callable, TypeVar

import httpx
from fastapi import HTTPException, status
from fastapi.responses import JSONResponse

try:
    from redis.asyncio import Redis
except ModuleNotFoundError:
    Redis = object  # type: ignore

from sqlalchemy.orm import Session as DbSession

from app.api.v1.chat.transport_handlers import (
    TransportResult,
    execute_claude_cli_transport,
    execute_http_transport,
    execute_sdk_transport,
)
from app.auth import AuthenticatedAPIKey
import app.context_store as context_store
from app.logging_config import logger
from app.provider.config import get_provider_config
from app.routing.scheduler import CandidateScore
from app.schemas import PhysicalModel
from app.settings import settings


# å®æ—¶æ•…éšœæ ‡è®°ç›¸å…³å¸¸é‡
FAILURE_KEY_PREFIX = "provider:failure:"

C = TypeVar("C", CandidateScore, PhysicalModel)


def _unwrap_candidate(candidate: C) -> PhysicalModel:
    if isinstance(candidate, CandidateScore):
        return candidate.upstream
    return candidate


async def _get_provider_failure_count(redis: Redis, provider_id: str) -> int:
    """è·å– Provider çš„æ•…éšœæ¬¡æ•°"""
    failure_key = f"{FAILURE_KEY_PREFIX}{provider_id}"
    try:
        count = await redis.get(failure_key)
        return int(count) if count else 0
    except Exception:
        return 0


async def _increment_provider_failure(redis: Redis, provider_id: str) -> int:
    """å¢åŠ  Provider çš„æ•…éšœæ¬¡æ•°ï¼Œå¹¶è®¾ç½®è¿‡æœŸæ—¶é—´"""
    failure_key = f"{FAILURE_KEY_PREFIX}{provider_id}"
    try:
        count = await redis.incr(failure_key)
        await redis.expire(failure_key, settings.provider_failure_cooldown_seconds)
        return int(count)
    except Exception:
        logger.exception("Failed to increment provider failure count for %s", provider_id)
        return 0


async def _clear_provider_failure(redis: Redis, provider_id: str) -> None:
    """æ¸…é™¤ Provider çš„æ•…éšœæ ‡è®°"""
    failure_key = f"{FAILURE_KEY_PREFIX}{provider_id}"
    try:
        await redis.delete(failure_key)
    except Exception:
        logger.exception("Failed to clear provider failure flag for %s", provider_id)


async def try_candidates_stream(
    *,
    candidates: Sequence[CandidateScore | PhysicalModel],
    client: httpx.AsyncClient,
    redis: Redis,
    db: DbSession,
    payload: dict[str, Any],
    logical_model_id: str,
    api_key: AuthenticatedAPIKey,
    session_id: str | None,
    on_first_chunk: Callable[[str, str], Awaitable[None]],  # (provider_id, model_id) -> None
):
    """
    éå†å€™é€‰ Providerï¼Œæ‰§è¡Œæµå¼è¯·æ±‚ï¼Œå¤±è´¥æ—¶é‡è¯•ä¸‹ä¸€ä¸ª
    
    å®æ—¶æ•…éšœæ ‡è®°æœºåˆ¶ï¼š
    - æ£€æŸ¥ Provider æ˜¯å¦åœ¨æ•…éšœå†·å´æœŸï¼ˆæœ€è¿‘ 60 ç§’å†…å¤±è´¥ >= 3 æ¬¡ï¼‰
    - å¤±è´¥æ—¶ç«‹å³æ ‡è®°ï¼Œé¿å…çŸ­æ—¶é—´å†…é‡å¤é€‰æ‹©
    - æˆåŠŸæ—¶æ¸…é™¤æ•…éšœæ ‡è®°
    
    Args:
        candidates: å€™é€‰ Provider åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
        on_first_chunk: æ”¶åˆ°ç¬¬ä¸€ä¸ª chunk æ—¶çš„å›è°ƒå‡½æ•°ï¼ˆç”¨äºç»‘å®š Sessionï¼‰
    
    Yields:
        æµå¼å“åº”çš„ chunk
    
    Raises:
        æ— å¼‚å¸¸æŠ›å‡ºï¼Œæ‰€æœ‰é”™è¯¯éƒ½é€šè¿‡ SSE æ ¼å¼è¿”å›
    """
    from app.api.v1.chat.transport_handlers_stream import (
        execute_claude_cli_stream,
        execute_http_stream,
        execute_sdk_stream,
    )
    
    last_status: int | None = None
    last_error_text: str | None = None
    skipped_count = 0
    
    for idx, cand in enumerate(candidates):
        upstream = _unwrap_candidate(cand)
        provider_id = upstream.provider_id
        model_id = upstream.model_id
        base_endpoint = upstream.endpoint
        is_last = idx == len(candidates) - 1
        
        # ğŸ”¥ å®æ—¶æ•…éšœæ£€æŸ¥ï¼šè·³è¿‡æ•…éšœå†·å´æœŸçš„ Provider
        failure_count = await _get_provider_failure_count(redis, provider_id)
        if failure_count >= settings.provider_failure_threshold:
            skipped_count += 1
            logger.warning(
                "â­ï¸  Skipping provider %s (stream): in failure cooldown (failures=%d/%d, cooldown=%ds)",
                provider_id,
                failure_count,
                settings.provider_failure_threshold,
                settings.provider_failure_cooldown_seconds,
            )
            continue
        
        provider_cfg = get_provider_config(provider_id)
        if provider_cfg is None:
            last_status = 503
            last_error_text = f"Provider '{provider_id}' is not configured"
            continue
        
        transport = getattr(provider_cfg, "transport", "http")
        
        logger.info(
            "ğŸ”„ Trying candidate (stream): provider=%s model=%s transport=%s (failures=%d/%d, candidate=%d/%d)",
            provider_id,
            model_id,
            transport,
            failure_count,
            settings.provider_failure_threshold,
            idx + 1,
            len(candidates),
        )
        
        # æ ¹æ®ä¼ è¾“æ–¹å¼é€‰æ‹©å¯¹åº”çš„æµå¼å¤„ç†å‡½æ•°
        stream_iterator = None
        
        if transport == "claude_cli":
            stream_iterator = execute_claude_cli_stream(
                client=client,
                redis=redis,
                db=db,
                provider_id=provider_id,
                model_id=model_id,
                payload=payload,
                logical_model_id=logical_model_id,
                api_key=api_key,
                session_id=session_id,
            )
        elif transport == "sdk":
            stream_iterator = execute_sdk_stream(
                redis=redis,
                db=db,
                provider_id=provider_id,
                model_id=model_id,
                payload=payload,
                logical_model_id=logical_model_id,
                api_key=api_key,
                session_id=session_id,
            )
        else:  # http
            stream_iterator = execute_http_stream(
                client=client,
                redis=redis,
                db=db,
                provider_id=provider_id,
                model_id=model_id,
                url=base_endpoint,
                payload=payload,
                logical_model_id=logical_model_id,
                api_key=api_key,
                session_id=session_id,
            )
        
        # å°è¯•æµå¼ä¼ è¾“
        first_chunk_seen = False
        try:
            async for chunk in stream_iterator:
                if not first_chunk_seen:
                    first_chunk_seen = True
                    # ğŸ”¥ æˆåŠŸï¼šæ¸…é™¤æ•…éšœæ ‡è®°
                    await _clear_provider_failure(redis, provider_id)
                    logger.info(
                        "âœ… Provider %s (stream) succeeded, failure flag cleared",
                        provider_id,
                    )
                    # è°ƒç”¨å›è°ƒï¼ˆç»‘å®š Sessionï¼‰
                    await on_first_chunk(provider_id, model_id)
                    logger.info(
                        "ğŸ“¡ Received first chunk from provider=%s model=%s",
                        provider_id,
                        model_id,
                    )
                
                yield chunk
            
            # æµå¼ä¼ è¾“æˆåŠŸå®Œæˆ
            logger.info(
                "ğŸ‰ Stream completed successfully: provider=%s model=%s",
                provider_id,
                model_id,
            )
            return
            
        except Exception as exc:
            # æµå¼ä¼ è¾“å¤±è´¥
            error_status = getattr(exc, "status_code", None)
            error_text = str(exc)
            
            last_status = error_status
            last_error_text = error_text
            
            # åˆ¤æ–­æ˜¯å¦å¯é‡è¯•
            retryable = _is_stream_error_retryable(exc, error_status)
            
            # ğŸ”¥ å®æ—¶æ•…éšœæ ‡è®°ï¼šå¯¹å¯é‡è¯•çš„æœåŠ¡å™¨é”™è¯¯ç«‹å³æ ‡è®°
            if retryable and error_status in (500, 502, 503, 504, 429):
                new_count = await _increment_provider_failure(redis, provider_id)
                logger.warning(
                    "âš ï¸  Provider %s (stream) failed with status %s, failure count: %d/%d (cooldown=%ds)",
                    provider_id,
                    error_status,
                    new_count,
                    settings.provider_failure_threshold,
                    settings.provider_failure_cooldown_seconds,
                )
            
            if retryable and not is_last:
                logger.warning(
                    "ğŸ” Stream failed (retryable): provider=%s model=%s status=%s, trying next",
                    provider_id,
                    model_id,
                    error_status,
                )
                continue
            else:
                # ä¸å¯é‡è¯•æˆ–å·²æ˜¯æœ€åä¸€ä¸ªå€™é€‰ï¼šè¿”å›é”™è¯¯
                logger.error(
                    "âŒ Stream failed (non-retryable or last): provider=%s model=%s status=%s",
                    provider_id,
                    model_id,
                    error_status,
                )
                
                # æ„å»ºé”™è¯¯å“åº”ï¼ˆSSE æ ¼å¼ï¼‰
                error_payload = {
                    "error": {
                        "type": "upstream_error",
                        "status": error_status,
                        "message": error_text,
                        "provider_id": provider_id,
                    }
                }
                error_chunk = f"data: {json.dumps(error_payload, ensure_ascii=False)}\n\n".encode("utf-8")
                
                await context_store.save_context(redis, session_id, payload, error_text)
                yield error_chunk
                return
    
    # æ‰€æœ‰å€™é€‰éƒ½å¤±è´¥
    message = f"All upstream providers failed for logical model '{logical_model_id}'"
    details: list[str] = []
    if skipped_count > 0:
        details.append(f"skipped={skipped_count} (in failure cooldown)")
    if last_status is not None:
        details.append(f"last_status={last_status}")
    if last_error_text:
        details.append(f"last_error={last_error_text}")
    detail_text = message
    if details:
        detail_text = f"{message}; " + ", ".join(details)
    
    logger.error(
        "ğŸ’¥ %s (total_candidates=%d, skipped=%d, tried=%d)",
        detail_text,
        len(candidates),
        skipped_count,
        len(candidates) - skipped_count,
    )
    
    # è¿”å›é”™è¯¯ï¼ˆSSE æ ¼å¼ï¼‰
    error_payload = {
        "error": {
            "type": "all_providers_failed",
            "message": detail_text,
            "last_status": last_status,
        }
    }
    error_chunk = f"data: {json.dumps(error_payload, ensure_ascii=False)}\n\n".encode("utf-8")
    
    await context_store.save_context(redis, session_id, payload, detail_text)
    yield error_chunk


def _is_stream_error_retryable(exc: Exception, status_code: int | None) -> bool:
    """åˆ¤æ–­æµå¼é”™è¯¯æ˜¯å¦å¯é‡è¯•"""
    # å¯¼å…¥ UpstreamStreamError
    from app.upstream import UpstreamStreamError
    
    if isinstance(exc, UpstreamStreamError):
        if status_code is None:
            return True
        # 5xx æœåŠ¡å™¨é”™è¯¯å¯é‡è¯•
        if 500 <= status_code < 600:
            return True
        # 429 é™æµå¯é‡è¯•
        if status_code == 429:
            return True
        # 408 è¯·æ±‚è¶…æ—¶å¯é‡è¯•
        if status_code == 408:
            return True
        return False
    
    # å…¶ä»–å¼‚å¸¸é»˜è®¤å¯é‡è¯•
    return True


async def try_candidates_non_stream(
    *,
    candidates: Sequence[CandidateScore | PhysicalModel],
    client: httpx.AsyncClient,
    redis: Redis,
    db: DbSession,
    payload: dict[str, Any],
    logical_model_id: str,
    api_key: AuthenticatedAPIKey,
    session_id: str | None,
    on_success: Callable[[str, str], Awaitable[None]],  # (provider_id, model_id) -> None
) -> JSONResponse:
    """
    éå†å€™é€‰ Providerï¼Œæ‰§è¡Œéæµå¼è¯·æ±‚ï¼Œå¤±è´¥æ—¶é‡è¯•ä¸‹ä¸€ä¸ª
    
    å®æ—¶æ•…éšœæ ‡è®°æœºåˆ¶ï¼š
    - æ£€æŸ¥ Provider æ˜¯å¦åœ¨æ•…éšœå†·å´æœŸï¼ˆæœ€è¿‘ 60 ç§’å†…å¤±è´¥ >= 3 æ¬¡ï¼‰
    - å¤±è´¥æ—¶ç«‹å³æ ‡è®°ï¼Œé¿å…çŸ­æ—¶é—´å†…é‡å¤é€‰æ‹©
    - æˆåŠŸæ—¶æ¸…é™¤æ•…éšœæ ‡è®°
    
    Args:
        candidates: å€™é€‰ Provider åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
        on_success: æˆåŠŸæ—¶çš„å›è°ƒå‡½æ•°ï¼ˆç”¨äºè®°å½•æŒ‡æ ‡ã€ç»‘å®š Session ç­‰ï¼‰
    
    Returns:
        æˆåŠŸçš„å“åº”
    
    Raises:
        HTTPException: æ‰€æœ‰å€™é€‰éƒ½å¤±è´¥æ—¶æŠ›å‡º
    """
    last_status: int | None = None
    last_error_text: str | None = None
    skipped_count = 0
    
    for cand in candidates:
        upstream = _unwrap_candidate(cand)
        provider_id = upstream.provider_id
        model_id = upstream.model_id
        base_endpoint = upstream.endpoint
        
        # ğŸ”¥ å®æ—¶æ•…éšœæ£€æŸ¥ï¼šè·³è¿‡æ•…éšœå†·å´æœŸçš„ Provider
        failure_count = await _get_provider_failure_count(redis, provider_id)
        if failure_count >= settings.provider_failure_threshold:
            skipped_count += 1
            logger.warning(
                "â­ï¸  Skipping provider %s: in failure cooldown (failures=%d/%d, cooldown=%ds)",
                provider_id,
                failure_count,
                settings.provider_failure_threshold,
                settings.provider_failure_cooldown_seconds,
            )
            continue
        
        provider_cfg = get_provider_config(provider_id)
        if provider_cfg is None:
            last_status = status.HTTP_503_SERVICE_UNAVAILABLE
            last_error_text = f"Provider '{provider_id}' is not configured"
            continue
        
        transport = getattr(provider_cfg, "transport", "http")
        
        logger.info(
            "ğŸ”„ Trying candidate: provider=%s model=%s transport=%s (failures=%d/%d)",
            provider_id,
            model_id,
            transport,
            failure_count,
            settings.provider_failure_threshold,
        )
        
        # æ ¹æ®ä¼ è¾“æ–¹å¼é€‰æ‹©å¯¹åº”çš„å¤„ç†å‡½æ•°
        result: TransportResult
        
        if transport == "claude_cli":
            result = await execute_claude_cli_transport(
                client=client,
                redis=redis,
                db=db,
                provider_id=provider_id,
                model_id=model_id,
                payload=payload,
                logical_model_id=logical_model_id,
                api_key=api_key,
                session_id=session_id,
            )
        elif transport == "sdk":
            result = await execute_sdk_transport(
                redis=redis,
                db=db,
                provider_id=provider_id,
                model_id=model_id,
                payload=payload,
                logical_model_id=logical_model_id,
                api_key=api_key,
                session_id=session_id,
            )
        else:  # http
            result = await execute_http_transport(
                client=client,
                redis=redis,
                db=db,
                provider_id=provider_id,
                model_id=model_id,
                url=base_endpoint,
                payload=payload,
                logical_model_id=logical_model_id,
                api_key=api_key,
                session_id=session_id,
            )
        
        # æ£€æŸ¥ç»“æœ
        if result.success:
            # ğŸ”¥ æˆåŠŸï¼šæ¸…é™¤æ•…éšœæ ‡è®°
            await _clear_provider_failure(redis, provider_id)
            logger.info(
                "âœ… Provider %s succeeded, failure flag cleared",
                provider_id,
            )
            
            # è°ƒç”¨å›è°ƒå¹¶è¿”å›
            await on_success(provider_id, model_id)
            return result.response
        
        # å¤±è´¥ï¼šè®°å½•é”™è¯¯
        last_status = result.status_code
        last_error_text = result.error_text
        
        # ğŸ”¥ å®æ—¶æ•…éšœæ ‡è®°ï¼šå¯¹å¯é‡è¯•çš„æœåŠ¡å™¨é”™è¯¯ç«‹å³æ ‡è®°
        if result.retryable and result.status_code in (500, 502, 503, 504, 429):
            new_count = await _increment_provider_failure(redis, provider_id)
            logger.warning(
                "âš ï¸  Provider %s failed with status %s, failure count: %d/%d (cooldown=%ds)",
                provider_id,
                result.status_code,
                new_count,
                settings.provider_failure_threshold,
                settings.provider_failure_cooldown_seconds,
            )
        
        if result.retryable:
            logger.warning(
                "ğŸ” Candidate failed (retryable): provider=%s model=%s status=%s, trying next",
                provider_id,
                model_id,
                result.status_code,
            )
            continue
        else:
            # ä¸å¯é‡è¯•çš„é”™è¯¯ï¼šç›´æ¥æŠ›å‡º
            logger.error(
                "âŒ Candidate failed (non-retryable): provider=%s model=%s status=%s",
                provider_id,
                model_id,
                result.status_code,
            )
            raise HTTPException(
                status_code=status.HTTP_502_BAD_GATEWAY,
                detail=f"Upstream error {result.status_code}: {result.error_text}",
            )
    
    # æ‰€æœ‰å€™é€‰éƒ½å¤±è´¥
    message = f"All upstream providers failed for logical model '{logical_model_id}'"
    details: list[str] = []
    if skipped_count > 0:
        details.append(f"skipped={skipped_count} (in failure cooldown)")
    if last_status is not None:
        details.append(f"last_status={last_status}")
    if last_error_text:
        details.append(f"last_error={last_error_text}")
    detail_text = message
    if details:
        detail_text = f"{message}; " + ", ".join(details)
    
    logger.error(
        "ğŸ’¥ %s (total_candidates=%d, skipped=%d, tried=%d)",
        detail_text,
        len(candidates),
        skipped_count,
        len(candidates) - skipped_count,
    )
    await context_store.save_context(redis, session_id, payload, detail_text)
    
    raise HTTPException(
        status_code=status.HTTP_502_BAD_GATEWAY,
        detail=detail_text,
    )


__all__ = [
    "try_candidates_non_stream",
    "try_candidates_stream",
]
